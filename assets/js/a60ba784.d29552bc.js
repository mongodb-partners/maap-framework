"use strict";(self.webpackChunkmaap_docs=self.webpackChunkmaap_docs||[]).push([[7200],{84:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"framework/agentic/components/data-loader","title":"Data Loader","description":"The maap-data-loader project is designed to streamline data ingestion and processing for the MongoDB Atlas Application Partner (MAAP) program. This tool provides a robust mechanism to load, transform, and manage data efficiently, ensuring seamless integration with MongoDB Atlas. It supports both structured and unstructured data processing, with built-in support for document processing, embeddings generation, and integration with various AI services.","source":"@site/docs/framework/agentic/components/data-loader.md","sourceDirName":"framework/agentic/components","slug":"/framework/agentic/components/data-loader","permalink":"/maap-framework/docs/framework/agentic/components/data-loader","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Agent Builder","permalink":"/maap-framework/docs/framework/agentic/components/agent-builder"},"next":{"title":"MCP Server","permalink":"/maap-framework/docs/framework/agentic/components/mcp-server"}}');var s=i(4848),o=i(8453);const t={},l="Data Loader",a={},c=[{value:"Features",id:"features",level:2},{value:"Reference Architecture",id:"reference-architecture",level:2},{value:"Component Description",id:"component-description",level:3},{value:"Input Layer",id:"input-layer",level:4},{value:"Processing Layer",id:"processing-layer",level:4},{value:"Storage Layer",id:"storage-layer",level:4},{value:"Utility Layer",id:"utility-layer",level:4},{value:"Project Structure",id:"project-structure",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Setup Instructions",id:"setup-instructions",level:2},{value:"Usage Examples",id:"usage-examples",level:2},{value:"Basic Document Processing",id:"basic-document-processing",level:3},{value:"Enterprise Pipeline Execution",id:"enterprise-pipeline-execution",level:3},{value:"Monitoring and Logging",id:"monitoring-and-logging",level:2},{value:"Container Deployment",id:"container-deployment",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Contributing",id:"contributing",level:2},{value:"License",id:"license",level:2}];function d(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"data-loader",children:"Data Loader"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"maap-data-loader"})," project is designed to streamline data ingestion and processing for the MongoDB Atlas Application Partner (MAAP) program. This tool provides a robust mechanism to load, transform, and manage data efficiently, ensuring seamless integration with MongoDB Atlas. It supports both structured and unstructured data processing, with built-in support for document processing, embeddings generation, and integration with various AI services."]}),"\n",(0,s.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Document Processing"}),": Automated processing of various document formats"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Embedding Generation"}),": Built-in support for generating embeddings using AI services"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"MongoDB Integration"}),": Direct integration with MongoDB Atlas for efficient data storage"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Configurable Pipeline"}),": Flexible pipeline configuration for different data processing needs"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Logging System"}),": Comprehensive logging system for tracking operations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Enterprise Support"}),": Dedicated enterprise features for large-scale deployments"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"reference-architecture",children:"Reference Architecture"}),"\n",(0,s.jsx)(n.mermaid,{value:'graph TB\n    subgraph Input ["Data Input Layer"]\n        DS["Data Sources"] --\x3e FU["File Upload"]\n    end\n\n    subgraph Processing ["Processing Layer"]\n        direction TB\n        subgraph ES["Enterprise Services"]\n            PE["Pipeline Executor"] --\x3e MI["MongoDB Ingest"]\n            PE --\x3e BC["Base Configs"]\n            BC --\x3e DL["Downloader"]\n            BC --\x3e IX["Indexer"]\n            BC --\x3e SC["Source Config"]\n        end\n\n        subgraph LS["Local Services"]\n            DS1["Document Service"] --\x3e BS["Bedrock Service"]\n            DS1 --\x3e ES1["Embedding Service"]\n        end\n    end\n\n    subgraph Storage ["Storage Layer"]\n        MD["MongoDB"] --\x3e UF["Uploaded Files"]\n        MD --\x3e LOG["Logs"]\n    end\n\n    subgraph Utils ["Utility Layer"]\n        EU["Error Utils"] --\x3e LG["Logger"]\n        FUT["File Utils"] --\x3e LG\n    end\n\n    Input --\x3e Processing\n    Processing --\x3e Storage\n    Utils --\x3e Processing\n    Utils --\x3e Storage\n\n    classDef primary fill:#2374AB,stroke:#2374AB,color:white\n    classDef secondary fill:#68A2CA,stroke:#68A2CA,color:white\n    classDef tertiary fill:#95B8D3,stroke:#95B8D3,color:white\n    classDef quaternary fill:#B8D0E1,stroke:#B8D0E1,color:black\n\n    class DS,FU primary\n    class PE,MI,DS1,BS,ES1 secondary\n    class MD,UF,LOG tertiary\n    class EU,FUT,LG quaternary'}),"\n",(0,s.jsx)(n.h3,{id:"component-description",children:"Component Description"}),"\n",(0,s.jsx)(n.h4,{id:"input-layer",children:"Input Layer"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Sources"}),": Various input sources including files, APIs, and streams"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"File Upload"}),": Handles file ingestion and initial validation"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"processing-layer",children:"Processing Layer"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Enterprise Services"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Pipeline Executor: Orchestrates data processing workflows"}),"\n",(0,s.jsx)(n.li,{children:"MongoDB Ingest: Handles data ingestion into MongoDB"}),"\n",(0,s.jsx)(n.li,{children:"Configuration Components: Manages processing settings"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Local Services"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Document Service: Processes and transforms documents"}),"\n",(0,s.jsx)(n.li,{children:"Bedrock Service: AWS Bedrock integration for AI capabilities"}),"\n",(0,s.jsx)(n.li,{children:"Embedding Service: Generates embeddings for documents"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"storage-layer",children:"Storage Layer"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"MongoDB"}),": Primary data store"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Uploaded Files"}),": Temporary storage for processed files"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Logs"}),": Application logging and monitoring"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"utility-layer",children:"Utility Layer"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Error Utils"}),": Error handling and reporting"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"File Utils"}),": File system operations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Logger"}),": Logging and monitoring utilities"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"project-structure",children:"Project Structure"}),"\n",(0,s.jsx)(n.p,{children:"The project is organized as follows:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"maap-data-loader/\n\u251c\u2500\u2500 app.py                 # Main application entry point\n\u251c\u2500\u2500 config.py             # Global configuration settings\n\u251c\u2500\u2500 Dockerfile            # Container definition for deployment\n\u251c\u2500\u2500 requirements.txt      # Python dependencies\n\u251c\u2500\u2500 enterprise/          # Enterprise-specific implementations\n\u2502   \u251c\u2500\u2500 mongodb_ingest.py     # MongoDB ingestion logic\n\u2502   \u251c\u2500\u2500 pipeline_executor.py  # Data pipeline execution\n\u2502   \u2514\u2500\u2500 util/                 # Enterprise utilities\n\u2502       \u251c\u2500\u2500 base_configs.py   # Base configuration classes\n\u2502       \u251c\u2500\u2500 builder.py        # Pipeline builder\n\u2502       \u2514\u2500\u2500 configs/          # Configuration components\n\u2502           \u251c\u2500\u2500 downloader.py # Data download configurations\n\u2502           \u251c\u2500\u2500 indexer.py    # Indexing configurations\n\u2502           \u2514\u2500\u2500 source.py     # Data source configurations\n\u251c\u2500\u2500 local/               # Local development components\n\u2502   \u251c\u2500\u2500 database/        # Database interactions\n\u2502   \u251c\u2500\u2500 models/          # Data models and schemas\n\u2502   \u251c\u2500\u2500 services/        # Core services\n\u2502   \u2502   \u251c\u2500\u2500 bedrock_service.py    # AWS Bedrock integration\n\u2502   \u2502   \u251c\u2500\u2500 document_service.py   # Document processing\n\u2502   \u2502   \u2514\u2500\u2500 embedding_service.py  # Embedding generation\n\u2502   \u2514\u2500\u2500 utils/           # Utility functions\n"})}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Python 3.8 or higher"}),"\n",(0,s.jsx)(n.li,{children:"MongoDB Atlas account"}),"\n",(0,s.jsx)(n.li,{children:"Docker (for containerized deployment)"}),"\n",(0,s.jsx)(n.li,{children:"AWS account (for Bedrock service integration)"}),"\n",(0,s.jsx)(n.li,{children:"Sufficient storage for document processing"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"setup-instructions",children:"Setup Instructions"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Clone the Repository"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/mongodb-partners/maap-data-loader.git\ncd maap-data-loader\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Quick Setup Using Make"}),(0,s.jsx)(n.br,{}),"\n","The project includes a Makefile for common operations. To get started quickly:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# View all available commands\nmake help\n\n# Set up virtual environment and install dependencies\nmake setup\n\n# Install additional development dependencies\nmake install-dev\n"})}),"\n",(0,s.jsx)(n.p,{children:"For other operations:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"make test        # Run tests\nmake lint        # Run linting and formatting\nmake run         # Run the application\nmake clean       # Clean up build artifacts\nmake docker-build # Build Docker image\nmake docker-run  # Run Docker container\nmake logs        # View application logs\nmake backup      # Backup processed data\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Manual Setup"}),(0,s.jsx)(n.br,{}),"\n","If not using Makefile, perform the following steps:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Set Up Python Environment"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -r requirements.txt\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Configure Environment Variables"}),(0,s.jsx)(n.br,{}),"\n","Create a ",(0,s.jsx)(n.code,{children:".env"})," file in the root directory with the following variables:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"MONGODB_URI=your_mongodb_connection_string\nAWS_ACCESS_KEY_ID=your_aws_access_key\nAWS_SECRET_ACCESS_KEY=your_aws_secret_key\nAWS_REGION=your_aws_region\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Configure Application Settings"}),(0,s.jsx)(n.br,{}),"\n","Update ",(0,s.jsx)(n.code,{children:"config.py"})," with your specific settings:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Database configurations"}),"\n",(0,s.jsx)(n.li,{children:"Processing pipeline settings"}),"\n",(0,s.jsx)(n.li,{children:"Document processing parameters"}),"\n",(0,s.jsx)(n.li,{children:"Embedding service configurations"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Run the Application"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python app.py\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"usage-examples",children:"Usage Examples"}),"\n",(0,s.jsx)(n.h3,{id:"basic-document-processing",children:"Basic Document Processing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from local.services.document_service import DocumentService\nfrom local.services.embedding_service import EmbeddingService\n\n# Initialize services\ndoc_service = DocumentService()\nembedding_service = EmbeddingService()\n\n# Process a document\nprocessed_doc = doc_service.process("path/to/document")\nembeddings = embedding_service.generate(processed_doc)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"enterprise-pipeline-execution",children:"Enterprise Pipeline Execution"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from enterprise.pipeline_executor import PipelineExecutor\nfrom enterprise.util.builder import PipelineBuilder\n\n# Configure pipeline\npipeline = PipelineBuilder()\\\n    .add_source("file_system")\\\n    .add_processor("document")\\\n    .add_sink("mongodb")\\\n    .build()\n\n# Execute pipeline\nexecutor = PipelineExecutor(pipeline)\nexecutor.run()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"monitoring-and-logging",children:"Monitoring and Logging"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Logs are stored in ",(0,s.jsx)(n.code,{children:"local/logs/MAAP-Loader.log"})]}),"\n",(0,s.jsx)(n.li,{children:"Monitor MongoDB operations through Atlas dashboard"}),"\n",(0,s.jsx)(n.li,{children:"Check processing status in application logs"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"container-deployment",children:"Container Deployment"}),"\n",(0,s.jsx)(n.p,{children:"Build and run using Docker:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker build -t maap-data-loader .\ndocker run -d --env-file .env maap-data-loader\n"})}),"\n",(0,s.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Always use virtual environments"}),"\n",(0,s.jsx)(n.li,{children:"Keep sensitive information in environment variables"}),"\n",(0,s.jsx)(n.li,{children:"Regular backup of processed data"}),"\n",(0,s.jsx)(n.li,{children:"Monitor system resources during large-scale processing"}),"\n",(0,s.jsx)(n.li,{children:"Use appropriate indexes in MongoDB for better query performance"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.p,{children:"Common issues and solutions:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Connection Errors"}),": Verify MongoDB URI and network connectivity"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Memory Issues"}),": Check document size and processing batch size"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Processing Errors"}),": Verify file formats and permissions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"AWS Integration"}),": Confirm AWS credentials and permissions"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"contributing",children:"Contributing"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Fork the repository"}),"\n",(0,s.jsx)(n.li,{children:"Create a feature branch"}),"\n",(0,s.jsx)(n.li,{children:"Submit a pull request with detailed description"}),"\n",(0,s.jsx)(n.li,{children:"Ensure tests pass and code meets style guidelines"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"license",children:"License"}),"\n",(0,s.jsx)(n.p,{children:"This project is licensed under the MIT License - see the LICENSE file for details."})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var r=i(6540);const s={},o=r.createContext(s);function t(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);