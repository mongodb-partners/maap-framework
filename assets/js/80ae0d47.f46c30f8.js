"use strict";(self.webpackChunkmaap_docs=self.webpackChunkmaap_docs||[]).push([[214],{737:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>h,frontMatter:()=>l,metadata:()=>a,toc:()=>t});var o=i(4848),r=i(8453);const l={},s="NVIDIA",a={id:"framework/partners/nvidia",title:"NVIDIA",description:"Introduction",source:"@site/docs/framework/partners/nvidia.md",sourceDirName:"framework/partners",slug:"/framework/partners/nvidia",permalink:"/maap-framework/docs/framework/partners/nvidia",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Ollama",permalink:"/maap-framework/docs/framework/partners/ollama"},next:{title:"App Modules",permalink:"/maap-framework/docs/category/app-modules"}},d={},t=[{value:"Introduction",id:"introduction",level:2},{value:"Deploying your model",id:"deploying-your-model",level:2},{value:"LLM Model",id:"llm-model",level:3},{value:"Usage with MAAP",id:"usage-with-maap",level:4},{value:"Config File:",id:"config-file",level:4},{value:"Environment Variables:",id:"environment-variables",level:4},{value:"Embedding Model",id:"embedding-model",level:3},{value:"Usage with MAAP",id:"usage-with-maap-1",level:4},{value:"Config File:",id:"config-file-1",level:4},{value:"Environment Variables:",id:"environment-variables-1",level:4},{value:"References",id:"references",level:3},{value:"Model Name",id:"model-name",level:5},{value:"NVIDIA_API_KEY",id:"nvidia_api_key",level:5},{value:"NVIDIA_BASE_URL",id:"nvidia_base_url",level:5}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"nvidia",children:"NVIDIA"}),"\n",(0,o.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,o.jsxs)(n.p,{children:["NVIDIA Inference Microservices (",(0,o.jsx)(n.a,{href:"https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/",children:"NIM"}),") is a collection of microservices that enables the deployment and serving of foundation models optimized for NVIDIA's accelerated computing platform. NVIDIA NIM provides efficient, production-ready AI model serving capabilities with excellent performance and compatibility with NVIDIA's hardware and software stack."]}),"\n",(0,o.jsx)(n.p,{children:"NVIDIA NIM allows for simplified deployment of a wide range of foundation models, including large language models (LLMs), multimodal models, and embedding models. These models are optimized to leverage NVIDIA's GPU acceleration, enabling high throughput and low latency in production environments."}),"\n",(0,o.jsx)(n.p,{children:"With NVIDIA NIM, users can access high-quality models through a standardized API interface that simplifies integration with existing systems and applications. The platform offers both cloud-based and on-premise deployment options, providing flexibility to meet various deployment requirements."}),"\n",(0,o.jsx)(n.h2,{id:"deploying-your-model",children:"Deploying your model"}),"\n",(0,o.jsx)(n.p,{children:"NVIDIA offers a variety of foundation models through the NIM platform, allowing you to select the most appropriate model for your specific use case."}),"\n",(0,o.jsx)(n.h3,{id:"llm-model",children:"LLM Model"}),"\n",(0,o.jsxs)(n.p,{children:["To access NVIDIA's NIM models, you'll need to set up your account and obtain the necessary API credentials. Visit the ",(0,o.jsx)(n.a,{href:"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/",children:"NVIDIA AI Enterprise"})," page to get started."]}),"\n",(0,o.jsx)(n.h4,{id:"usage-with-maap",children:"Usage with MAAP"}),"\n",(0,o.jsx)(n.p,{children:"To use NVIDIA NIM models with the MAAP framework, you need to configure the following components:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.h4,{id:"config-file",children:"Config File:"}),"\n",(0,o.jsxs)(n.p,{children:["Add the following values to your ",(0,o.jsx)(n.code,{children:"config.yaml"})," file in the LLM section:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"llms:\n    class_name: NvidiaModel\n    model_name: <check_references_below>\n    max_tokens: <integer_value> [Optional]\n    temperature: <float_value> [Optional]\n    top_p: <float_value> [Optional]\n    frequency_penalty: <float_value> [Optional]\n    presence_penalty: <float_value> [Optional]\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.h4,{id:"environment-variables",children:"Environment Variables:"}),"\n",(0,o.jsxs)(n.p,{children:["Add the following values to your ",(0,o.jsx)(n.code,{children:".env"})," file in the ",(0,o.jsx)(n.code,{children:"builder/partnerproduct/"})," directory:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"NVIDIA_API_KEY=<your_nvidia_api_key>\nNVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1\n"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"embedding-model",children:"Embedding Model"}),"\n",(0,o.jsx)(n.p,{children:"NVIDIA provides powerful embedding models that can be used with the MAAP framework for vector representations of text."}),"\n",(0,o.jsx)(n.h4,{id:"usage-with-maap-1",children:"Usage with MAAP"}),"\n",(0,o.jsx)(n.p,{children:"To use NVIDIA embeddings with the MAAP framework, configure your system as follows:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.h4,{id:"config-file-1",children:"Config File:"}),"\n",(0,o.jsxs)(n.p,{children:["Add the following values to your ",(0,o.jsx)(n.code,{children:"config.yaml"})," file in the embedding section:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'embedding:\n    class_name: NvidiaEmbeddings\n    model_name: <check_references_below>\n    truncate: "NONE" [Optional]\n    encoding_format: "float" [Optional]\n    input_type: "query" # or "passage" depending on your use case [Optional]\n'})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.h4,{id:"environment-variables-1",children:"Environment Variables:"}),"\n",(0,o.jsx)(n.p,{children:"Use the same environment variables as for the LLM model:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"NVIDIA_API_KEY=<your_nvidia_api_key>\nNVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1\n"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"references",children:"References"}),"\n",(0,o.jsx)(n.p,{children:"Here's information on how to find the correct values for your MAAP framework:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.h5,{id:"model-name",children:"Model Name"}),"\n",(0,o.jsx)(n.p,{children:"NVIDIA offers several models through NIM. Common models include:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"nvidia/llama-3.1-nemotron-70b-instruct"})," - High performance instruction-tuned LLM for general tasks"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"nvidia/llama-3.2-nv-embedqa-1b-v2"})," - Embedding model optimized for retrieval tasks (2048 dimensions)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"nvidia/nv-embed-v1"})," - General purpose embedding model (4096 dimensions)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"nvidia/nv-embedqa-e5-v5"})," - Embedding model for question-answering (1024 dimensions)"]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["For a complete list of available models, consult the ",(0,o.jsx)(n.a,{href:"https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/",children:"NVIDIA NIM documentation"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.h5,{id:"nvidia_api_key",children:"NVIDIA_API_KEY"}),"\n",(0,o.jsxs)(n.p,{children:["You can obtain your API key by registering for NVIDIA AI Enterprise and accessing the NIM platform. Follow the instructions on the ",(0,o.jsx)(n.a,{href:"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/",children:"NVIDIA AI Enterprise"})," site."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.h5,{id:"nvidia_base_url",children:"NVIDIA_BASE_URL"}),"\n",(0,o.jsxs)(n.p,{children:["The default base URL is ",(0,o.jsx)(n.code,{children:"https://integrate.api.nvidia.com/v1"}),". This may change based on your deployment options or region."]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>a});var o=i(6540);const r={},l=o.createContext(r);function s(e){const n=o.useContext(l);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(l.Provider,{value:n},e.children)}}}]);